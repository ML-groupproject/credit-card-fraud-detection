# credit-card-fraud-detection
Aim: To detect fraudulent credit card transactions using different Machine Learning models by training them to learn patterns behind fraudulent behaviour.

# Dataset
Contains the link to the “Credit Card Fraud Detection” dataset that is publicly available on Kaggle.


# Data Visualization
Visualisation of the dataset by using histogram distribution and correlation of different features using heatmap.

# Models
1. Random Forest:
   A random forest is a supervised machine learning algorithm that can be used for both classification and regression tasks. The model works by sampling the training dataset, building multiple decision trees, and then having the output of the decision trees determine a prediction.

2. CatBoost:
   The CatBoost algorithms works by building decision trees consecutively and minimizing loss with each new decision tree that is built. It is designed to work well with imbalanced data, which makes the algorithm perfect for use in fraud detection.

3. Isolation forest:
   Isolation Forest is an unsupervised learning method, meaning that it does not require any truth-marking to make predictions, and only learns from patterns it finds in the training data. It is a tree-based algorithm used for anomaly detection. The algorithm works by using decision trees to isolate outliers from the data.

4. Logistic Regression:
   Logistic regression is a fundamental classification technique. It is an algorithm that measures the probability of a binary response as the value of response variable based on the mathematical equation relating it with the predictor variables.
   
5. XGBoost Method:
   XGBoost is a powerful approach for building supervised regression models. It is based on the Gradient Boosting model which uses the boosting technique of ensemble learning where the underfitted data of the weak learners are passed on to the strong learners to increase the strength and accuracy of the model.

6. KNN Classifier:
   K-nearest neighbor classifier is one of the introductory supervised classifiers. K-nearest neighbor classifier algorithms predict the target label by finding the nearest neighbor class. The closest class is identified using the distance measures like Euclidean distance.
   
7. GaussianNB:
   Gaussian Naive Bayes is a variant of Naive Bayes that follows Gaussian normal distribution and supports continuous data. Naive Bayes are a group of supervised machine learning classification algorithms based on the Bayes theorem. It is a simple classification technique, but has high functionality.
  
# CONCLUSION  




